{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n",
    "                              RandomForestClassifier, RandomForestRegressor)\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, Ridge\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, mean_absolute_error, r2_score)\n",
    "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV,\n",
    "                                     train_test_split)\n",
    "from sklearn.preprocessing import (LabelEncoder, MinMaxScaler, OneHotEncoder,\n",
    "                                   PolynomialFeatures, RobustScaler,\n",
    "                                   StandardScaler)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(39923, 16)"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# import data\n",
    "dataset_og = pd.read_csv('Data\\Measurements-Transformed')\n",
    "\n",
    "# kopie maken indien we iets van de originele data nodig hebben\n",
    "dataset = dataset_og.copy()\n",
    "dataset = dataset.sort_values(by=['ID', 'Measurement_Age'], ascending = False)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keuze target en aantal sliding window records\n",
    "target = 'Sph-Far-R'\n",
    "prefAmountRecords = 3"
   ]
  },
  {
   "source": [
    "### Sliding window\n",
    "\n",
    "#### met var prefAmountRecords kan je kiezen welke minimum records je wil, naargelang deze grafiek is de keuze te maken:\n",
    "![Graph](https://i.imgur.com/82t9CSH.png)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dropped 24929 records of 39923, 37% remaining\n"
    }
   ],
   "source": [
    "# Drop waardes die minder dan n* records hebben\n",
    "preDrop = dataset.shape[0]\n",
    "dataset = dataset.groupby('ID').filter(lambda x: len(x) >= prefAmountRecords)\n",
    "dataset = dataset.groupby('ID').head(prefAmountRecords)\n",
    "postDrop = dataset.shape[0]\n",
    "\n",
    "print(f'Dropped {preDrop-postDrop} records of {preDrop}, {math.floor((postDrop/preDrop)*100)}% remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30.168344020843506\n"
    }
   ],
   "source": [
    "# Sliding window\n",
    "start = time.time()\n",
    "# dataset = dataset[:500]\n",
    "df_f = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for uniqueId in dataset['ID'].unique():\n",
    "    for i in range(prefAmountRecords):\n",
    "        if len(dataset.loc[dataset['ID'] == uniqueId]) >= prefAmountRecords:\n",
    "            if i == 0:\n",
    "                df = pd.DataFrame(dataset.loc[dataset['ID'] == uniqueId].iloc[i]).T\n",
    "                df.columns = ['ID', 'Sex'] + list((n + f'_{i}') for n in dataset.columns[2:])\n",
    "            else:\n",
    "                df_t = pd.DataFrame(dataset.loc[dataset['ID'] == uniqueId].iloc[i][2:]).T\n",
    "                df_t.columns = list((n + f'_{i}') for n in dataset.columns[2:])\n",
    "                df = pd.concat([df.reset_index(drop=True), df_t.reset_index(drop=True)], axis = 1)\n",
    "    df_f = df_f.append(df)\n",
    "\n",
    "dataset = df_f.copy()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "dataset.head(5)\n",
    "dataset.to_csv(f'Data\\\\Measurements-Sliding-Window-{prefAmountRecords}', index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([], dtype=int64), array([], dtype=int64))"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "for coll in dataset.columns:\n",
    "    coll = np.nan_to_num(coll)\n",
    "pd.DataFrame(dataset).fillna(0, inplace=True)\n",
    "np.where(np.isnan(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "r2 score =  0.7612018613679994\n"
    }
   ],
   "source": [
    "# Linear regression\n",
    "lregModel = linear_model.LinearRegression()\n",
    "lregModel.fit(X_train, y_train)\n",
    "print('r2 score = ', lregModel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lreg + Poly = beter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dimensie van polynomial data op graad 1: (3998, 31)\nBest r2 :  0.820093996697312\nBest parameters : {'tol': 214.28577142857142, 'solver': 'auto', 'fit_intercept': False, 'alpha': 183.67353265306122} after 500 searches\n"
    }
   ],
   "source": [
    "# hogere orde features\n",
    "graad = 1\n",
    "n_iter_search = 500\n",
    "parameters = {\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], \n",
    "    'alpha': np.linspace(0.0001,n_iter_search,50), \n",
    "    'tol': np.linspace(0.0001,n_iter_search,50), \n",
    "    'fit_intercept': [True, False]\n",
    "    }\n",
    "\n",
    "# Polynominal features aanmaken\n",
    "polyModel = PolynomialFeatures(graad)\n",
    "polyModel.fit(X_train, X_test)\n",
    "X_train_poly = polyModel.transform(X_train)\n",
    "X_test_poly = polyModel.transform(X_test)\n",
    "print(f'Dimensie van polynomial data op graad {graad}: {X_train_poly.shape}')\n",
    "\n",
    "# Cross-validation via random search\n",
    "lregPolyModel = Ridge()\n",
    "lregPolyRandomModel = RandomizedSearchCV(lregPolyModel, param_distributions=parameters, cv=5, n_iter=n_iter_search, n_jobs = -1, verbose=0)\n",
    "lregPolyRandomModel = lregPolyRandomModel.fit(X_train_poly, y_train)\n",
    "\n",
    "print('Best r2 : ', lregPolyRandomModel.best_score_)\n",
    "print(f'Best parameters : {lregPolyRandomModel.best_params_} after {n_iter_search} searches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gescalede Lreg = slechter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitsen in training set en test set\n",
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "r2 score =  0.7612018613679452\n"
    }
   ],
   "source": [
    "# Linear regression\n",
    "lregModel = linear_model.LinearRegression()\n",
    "lregModel.fit(X_train, y_train)\n",
    "print('r2 score = ', lregModel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gescalede Lreg + Poly = slechter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitsen in training set en test set\n",
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dimensie van polynomial data op graad 1: (3998, 31)\nBest r2 :  0.8197057396121817\nBest parameters : {'tol': 214.28577142857142, 'solver': 'auto', 'fit_intercept': True, 'alpha': 40.81641836734694} after 500 searches\n"
    }
   ],
   "source": [
    "# hogere orde features\n",
    "graad = 1\n",
    "n_iter_search = 500\n",
    "parameters = {\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], \n",
    "    'alpha': np.linspace(0.0001,n_iter_search,50), \n",
    "    'tol': np.linspace(0.0001,n_iter_search,50), \n",
    "    'fit_intercept': [True, False]\n",
    "    }\n",
    "\n",
    "# Polynominal features aanmaken\n",
    "polyModel = PolynomialFeatures(graad)\n",
    "polyModel.fit(X_train, X_test)\n",
    "X_train_poly = polyModel.transform(X_train)\n",
    "X_test_poly = polyModel.transform(X_test)\n",
    "print(f'Dimensie van polynomial data op graad {graad}: {X_train_poly.shape}')\n",
    "\n",
    "# Cross-validation via random search\n",
    "lregPolyModel = Ridge()\n",
    "lregPolyRandomModel = RandomizedSearchCV(lregPolyModel, param_distributions=parameters, cv=5, n_iter=n_iter_search, n_jobs = -1, verbose=0)\n",
    "lregPolyRandomModel = lregPolyRandomModel.fit(X_train_poly, y_train)\n",
    "\n",
    "print('Best r2 : ', lregPolyRandomModel.best_score_)\n",
    "print(f'Best parameters : {lregPolyRandomModel.best_params_} after {n_iter_search} searches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7795784517360235\n"
    }
   ],
   "source": [
    "RFR_model = RandomForestRegressor(n_estimators=100)\n",
    "RFR_model.fit(X_train, y_train)\n",
    "\n",
    "print(RFR_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression + poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dimensie van polynomial data op graad 1: (3998, 31)\n"
    }
   ],
   "source": [
    "graad = 1\n",
    "\n",
    "# Polynominal features aanmaken\n",
    "polyModel = PolynomialFeatures(graad)\n",
    "polyModel.fit(X_train, X_test)\n",
    "X_train_poly = polyModel.transform(X_train)\n",
    "X_test_poly = polyModel.transform(X_test)\n",
    "print(f'Dimensie van polynomial data op graad {graad}: {X_train_poly.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7821074426241585\n"
    }
   ],
   "source": [
    "RFR_model = RandomForestRegressor(n_estimators=100)\n",
    "RFR_model.fit(X_train, y_train)\n",
    "\n",
    "print(RFR_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  3.2min\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  6.1min finished\n{'n_estimators': 100, 'min_weight_fraction_leaf': 0.0, 'max_features': 'sqrt', 'max_depth': 100.0, 'criterion': 'mse'}\n0.8264957481372229\n"
    }
   ],
   "source": [
    "n_iter_search = 50\n",
    "\n",
    "# Cross-validation via grid search - hoogste balanced accuracy\n",
    "model = RandomForestRegressor(n_estimators=n_estimators)\n",
    "paramaters = {'n_estimators':[100, 500, 1000], 'criterion':['mse', 'mae'], 'max_depth': np.linspace(1, 100), 'min_weight_fraction_leaf':np.linspace(0.0, 1.0), 'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "random_search = RandomizedSearchCV(estimator = model, \n",
    "                           param_distributions = paramaters,\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 5,\n",
    "                           n_iter = n_iter_search)\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression + tuning + poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitsen in training set en test set\n",
    "y = dataset[f'{target}_{prefAmountRecords-1}']\n",
    "X = dataset.drop([c for c in dataset.columns if f'_{prefAmountRecords-1}' in c], axis=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dimensie van polynomial data op graad 1: (3998, 31)\n"
    }
   ],
   "source": [
    "graad = 1\n",
    "\n",
    "# Polynominal features aanmaken\n",
    "polyModel = PolynomialFeatures(graad)\n",
    "polyModel.fit(X_train, X_test)\n",
    "X_train_poly = polyModel.transform(X_train)\n",
    "X_test_poly = polyModel.transform(X_test)\n",
    "print(f'Dimensie van polynomial data op graad {graad}: {X_train_poly.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   19.0s\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.4min finished\n{'n_estimators': 1000, 'min_weight_fraction_leaf': 0.0, 'max_features': 'sqrt', 'max_depth': 21.204081632653057, 'criterion': 'mse'}\n0.8287650670522225\n"
    }
   ],
   "source": [
    "n_iter_search = 50\n",
    "\n",
    "# Cross-validation via grid search - hoogste balanced accuracy\n",
    "model = RandomForestRegressor(n_estimators=n_estimators)\n",
    "paramaters = {'n_estimators':[100, 500, 1000], 'criterion':['mse', 'mae'], 'max_depth': np.linspace(1, 100), 'min_weight_fraction_leaf':np.linspace(0.0, 1.0), 'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "random_search = RandomizedSearchCV(estimator = model, \n",
    "                           param_distributions = paramaters,\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 5,\n",
    "                           n_iter = n_iter_search)\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bitccd76772a05f4a818b85475ead832635",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}